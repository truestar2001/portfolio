{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1d8AfjLvI7RKQ-5EKkyN11ns7Rp04EP0Z","authorship_tag":"ABX9TyPxNYr6qJvnl//a1ADbHFkL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUx0BRsAm-4B","executionInfo":{"status":"ok","timestamp":1652607378299,"user_tz":-540,"elapsed":28,"user":{"displayName":"윤진성","userId":"16392474644452501339"}},"outputId":"54588cce-5937-4931-bdf9-67dcd7243d43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using PyTorch version: 1.11.0+cu113  Device: cuda\n"]}],"source":["''' 1. Module Import '''\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","\n","from torchvision import transforms, datasets\n","''' 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n","if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","else:\n","    DEVICE = torch.device('cpu')\n","print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","EPOCHS = 10\n","\n","class CustomDataset(Dataset):\n","\tdef __init__(self, csv_path):\n","\t\tdf = pd.read_csv(csv_path)\n","\t\t\n","\t\tself.inp = df.iloc[:, :3].values\n","\t\tself.outp = df.iloc[:,-1].values.reshape(-1,1)\n","\t\n","\tdef __len__(self):\n","\t\t# 가지고 있는 데이터셋의 길이를 반환한다.\n","\t\treturn len(self.inp) # 1314\n","\n","\tdef __getitem__(self,idx):\n","\t\tinp = torch.FloatTensor(self.inp[idx])\n","\t\toutp = torch.LongTensor(self.outp[idx])\n","\t\treturn inp, outp # 해당하는 idx(인덱스)의 input과 output 데이터를 반환한다.\n","\n","''' 3. MNIST 데이터 다운로드 (Train set, Test set 분리하기) '''\n","PATH_TRAIN = './drive/MyDrive/WELT/data_set_train.csv'\n","PATH_TEST = './drive/MyDrive/WELT/data_set_test.csv'\n","\n","train_dataset = CustomDataset(PATH_TRAIN)\n","test_dataset = CustomDataset(PATH_TEST)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle = True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle = False)"],"metadata":{"id":"vt2Th3Y6nfZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (X_train, y_train) in train_loader:\n","    print('X_train:', X_train.size(), 'type:', X_train.type())\n","    print('y_train:', y_train.size(), 'type:', y_train.type())\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TT__gcYXy4pV","executionInfo":{"status":"ok","timestamp":1652607378302,"user_tz":-540,"elapsed":15,"user":{"displayName":"윤진성","userId":"16392474644452501339"}},"outputId":"22492871-3688-4515-d413-2bf3b61fe3ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: torch.Size([32, 3]) type: torch.FloatTensor\n","y_train: torch.Size([32, 1]) type: torch.LongTensor\n"]}]},{"cell_type":"code","source":["for (X_test, y_test) in test_loader:\n","    print('X_test:', X_train.size(), 'type:', X_train.type())\n","    print('y_test:', y_train.size(), 'type:', y_train.type())\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcnQX4wrzIZW","executionInfo":{"status":"ok","timestamp":1652607378739,"user_tz":-540,"elapsed":6,"user":{"displayName":"윤진성","userId":"16392474644452501339"}},"outputId":"d757cff3-75a0-4796-bfdf-ab03aa8299a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_test: torch.Size([32, 3]) type: torch.FloatTensor\n","y_test: torch.Size([32, 1]) type: torch.LongTensor\n"]}]},{"cell_type":"code","source":["''' 6. Multi Layer Perceptron (MLP) 모델 설계하기 '''\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(3, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 9)\n","        self.dropout_prob = 0.5\n","        self.batch_norm1 = nn.BatchNorm1d(512)\n","        self.batch_norm2 = nn.BatchNorm1d(256)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 3)\n","        x = self.fc1(x)\n","        x = self.batch_norm1(x)\n","        x = F.relu(x)\n","        x = F.dropout(x, training = self.training, p = self.dropout_prob)\n","        x = self.fc2(x)\n","        x = self.batch_norm2(x)\n","        x = F.relu(x)\n","        x = F.dropout(x, training = self.training, p = self.dropout_prob)\n","        x = self.fc3(x)\n","        x = F.log_softmax(x, dim = 1)\n","        return x"],"metadata":{"id":"mKllJQir3Ptn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' 7. Optimizer, Objective Function 설정하기 '''\n","import torch.nn.init as init\n","def weight_init(m):\n","    if isinstance(m, nn.Linear):\n","        init.kaiming_uniform_(m.weight.data)\n","\n","model = Net().to(DEVICE)\n","model.apply(weight_init)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xsJjPOa3neC","executionInfo":{"status":"ok","timestamp":1652607379588,"user_tz":-540,"elapsed":26,"user":{"displayName":"윤진성","userId":"16392474644452501339"}},"outputId":"b0d4b02a-188e-4430-c996-110cf00880cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (fc1): Linear(in_features=3, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=9, bias=True)\n","  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n"]}]},{"cell_type":"code","source":["''' 8. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n","def train(model, train_loader, optimizer, log_interval):\n","    model.train()\n","    for batch_idx, (feature, label) in enumerate(train_loader):\n","        feature = feature.to(DEVICE)\n","        label = label.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(feature)\n","        loss = criterion(output, label.squeeze(dim=-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % log_interval == 0:\n","            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n","                epoch, batch_idx * len(feature), \n","                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n","                loss.item()))"],"metadata":{"id":"K74sjg4Q3r0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for feature, label in test_loader:\n","            feature = feature.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(feature)\n","            test_loss += criterion(output, label.squeeze(dim=-1)).item()\n","            prediction = output.max(1, keepdim = True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","    \n","    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"],"metadata":{"id":"i1HC4Pjq4Zqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' 10. MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n","for epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer, log_interval = 200)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n","        epoch, test_loss, test_accuracy))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEBmu3y44kJo","executionInfo":{"status":"ok","timestamp":1652607406894,"user_tz":-540,"elapsed":23460,"user":{"displayName":"윤진성","userId":"16392474644452501339"}},"outputId":"0debbad4-0a00-43fd-fd8c-8f4e2a888509"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/27288 (0%)]\tTrain Loss: 2.810086\n","Train Epoch: 1 [6400/27288 (23%)]\tTrain Loss: 0.892870\n","Train Epoch: 1 [12800/27288 (47%)]\tTrain Loss: 0.862045\n","Train Epoch: 1 [19200/27288 (70%)]\tTrain Loss: 0.701074\n","Train Epoch: 1 [25600/27288 (94%)]\tTrain Loss: 1.150988\n","\n","[EPOCH: 1], \tTest Loss: 0.6235, \tTest Accuracy: 73.98 % \n","\n","Train Epoch: 2 [0/27288 (0%)]\tTrain Loss: 0.887027\n","Train Epoch: 2 [6400/27288 (23%)]\tTrain Loss: 0.947695\n","Train Epoch: 2 [12800/27288 (47%)]\tTrain Loss: 0.439550\n","Train Epoch: 2 [19200/27288 (70%)]\tTrain Loss: 0.859310\n","Train Epoch: 2 [25600/27288 (94%)]\tTrain Loss: 0.748310\n","\n","[EPOCH: 2], \tTest Loss: 0.5816, \tTest Accuracy: 80.27 % \n","\n","Train Epoch: 3 [0/27288 (0%)]\tTrain Loss: 0.556183\n","Train Epoch: 3 [6400/27288 (23%)]\tTrain Loss: 1.254200\n","Train Epoch: 3 [12800/27288 (47%)]\tTrain Loss: 1.272072\n","Train Epoch: 3 [19200/27288 (70%)]\tTrain Loss: 0.798873\n","Train Epoch: 3 [25600/27288 (94%)]\tTrain Loss: 0.818539\n","\n","[EPOCH: 3], \tTest Loss: 0.5789, \tTest Accuracy: 79.49 % \n","\n","Train Epoch: 4 [0/27288 (0%)]\tTrain Loss: 0.733457\n","Train Epoch: 4 [6400/27288 (23%)]\tTrain Loss: 1.196700\n","Train Epoch: 4 [12800/27288 (47%)]\tTrain Loss: 0.809817\n","Train Epoch: 4 [19200/27288 (70%)]\tTrain Loss: 1.021852\n","Train Epoch: 4 [25600/27288 (94%)]\tTrain Loss: 0.635122\n","\n","[EPOCH: 4], \tTest Loss: 0.5891, \tTest Accuracy: 79.16 % \n","\n","Train Epoch: 5 [0/27288 (0%)]\tTrain Loss: 0.790695\n","Train Epoch: 5 [6400/27288 (23%)]\tTrain Loss: 0.572720\n","Train Epoch: 5 [12800/27288 (47%)]\tTrain Loss: 0.574594\n","Train Epoch: 5 [19200/27288 (70%)]\tTrain Loss: 0.552835\n","Train Epoch: 5 [25600/27288 (94%)]\tTrain Loss: 0.874505\n","\n","[EPOCH: 5], \tTest Loss: 0.5594, \tTest Accuracy: 79.35 % \n","\n","Train Epoch: 6 [0/27288 (0%)]\tTrain Loss: 1.245551\n","Train Epoch: 6 [6400/27288 (23%)]\tTrain Loss: 0.753129\n","Train Epoch: 6 [12800/27288 (47%)]\tTrain Loss: 0.541879\n","Train Epoch: 6 [19200/27288 (70%)]\tTrain Loss: 0.480086\n","Train Epoch: 6 [25600/27288 (94%)]\tTrain Loss: 0.706702\n","\n","[EPOCH: 6], \tTest Loss: 0.5644, \tTest Accuracy: 78.94 % \n","\n","Train Epoch: 7 [0/27288 (0%)]\tTrain Loss: 0.789278\n","Train Epoch: 7 [6400/27288 (23%)]\tTrain Loss: 0.746268\n","Train Epoch: 7 [12800/27288 (47%)]\tTrain Loss: 1.163876\n","Train Epoch: 7 [19200/27288 (70%)]\tTrain Loss: 0.611775\n","Train Epoch: 7 [25600/27288 (94%)]\tTrain Loss: 0.521026\n","\n","[EPOCH: 7], \tTest Loss: 0.5473, \tTest Accuracy: 78.89 % \n","\n","Train Epoch: 8 [0/27288 (0%)]\tTrain Loss: 0.675797\n","Train Epoch: 8 [6400/27288 (23%)]\tTrain Loss: 0.676032\n","Train Epoch: 8 [12800/27288 (47%)]\tTrain Loss: 0.488416\n","Train Epoch: 8 [19200/27288 (70%)]\tTrain Loss: 0.954082\n","Train Epoch: 8 [25600/27288 (94%)]\tTrain Loss: 0.864825\n","\n","[EPOCH: 8], \tTest Loss: 0.5385, \tTest Accuracy: 79.68 % \n","\n","Train Epoch: 9 [0/27288 (0%)]\tTrain Loss: 0.473722\n","Train Epoch: 9 [6400/27288 (23%)]\tTrain Loss: 0.686600\n","Train Epoch: 9 [12800/27288 (47%)]\tTrain Loss: 0.760252\n","Train Epoch: 9 [19200/27288 (70%)]\tTrain Loss: 0.701629\n","Train Epoch: 9 [25600/27288 (94%)]\tTrain Loss: 0.594954\n","\n","[EPOCH: 9], \tTest Loss: 0.5283, \tTest Accuracy: 81.63 % \n","\n","Train Epoch: 10 [0/27288 (0%)]\tTrain Loss: 0.595847\n","Train Epoch: 10 [6400/27288 (23%)]\tTrain Loss: 0.812984\n","Train Epoch: 10 [12800/27288 (47%)]\tTrain Loss: 0.797070\n","Train Epoch: 10 [19200/27288 (70%)]\tTrain Loss: 0.739474\n","Train Epoch: 10 [25600/27288 (94%)]\tTrain Loss: 0.637642\n","\n","[EPOCH: 10], \tTest Loss: 0.5476, \tTest Accuracy: 77.70 % \n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"8hmNgmvl4nLo"},"execution_count":null,"outputs":[]}]}